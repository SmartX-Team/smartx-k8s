---
## Install Prometheus Operator CRDs
##
crds:
  ## The CRD upgrade job mitigates the limitation of helm not being able to upgrade CRDs.
  ## The job will apply the CRDs to the cluster before the operator is deployed, using helm hooks.
  ## It deploy a corresponding clusterrole, clusterrolebinding and serviceaccount to apply the CRDs.
  ## This feature is in preview, off by default and may change in the future.
  upgradeJob:
    ## Assign custom affinity rules to the upgrade-crd job
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
    ##
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: node-role.kubernetes.io/kiss
                  operator: In
                  values:
                    - ControlPlane

## Configuration for alertmanager
## ref: https://prometheus.io/docs/alerting/alertmanager/
##
alertmanager:
  ## Settings affecting alertmanagerSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#alertmanagerspec
  ##
  alertmanagerSpec:
    ## Storage is the definition of how storage will be used by the Alertmanager instances.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
    ##
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: ceph-block
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 50Gi

## Affinity for pod assignment (evaluated as template)
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
##
affinity:
  nodeAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      # KISS normal control plane nodes should be preferred
      - weight: 1
        preference:
          matchExpressions:
            - key: node-role.kubernetes.io/kiss-ephemeral-control-plane
              operator: DoesNotExist
      # KISS gateway nodes should be more preferred
      - weight: 2
        preference:
          matchExpressions:
            - key: node-role.kubernetes.io/kiss
              operator: In
              values:
                - Compute
      # KISS gateway nodes should be more preferred
      - weight: 4
        preference:
          matchExpressions:
            - key: node-role.kubernetes.io/kiss
              operator: In
              values:
                - Gateway
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: node-role.kubernetes.io/kiss
              operator: In
              values:
                - Compute
                - ControlPlane
                - Gateway

## Using default values from https://github.com/grafana/helm-charts/blob/main/apps/grafana/values.yaml
##
grafana:
  ingress:
    ## If true, Grafana Ingress will be created
    ##
    enabled: true

    ## Annotations for Grafana Ingress
    ##
    annotations:
      nginx.ingress.kubernetes.io/cors-allow-origin: "*"
      nginx.ingress.kubernetes.io/enable-cors: "true"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"

    ## Path for grafana ingress
    path: /

    # pathType is only for k8s >= 1.1=
    pathType: Prefix

  ## Configure additional grafana datasources (passed through tpl)
  ## ref: http://docs.grafana.org/administration/provisioning/#datasources
  additionalDataSources:
    # # this follows https://github.com/grafana/tns/blob/main/production/docker-compose/datasources.yaml
    # # see also the additional links to Grafana docs specific for data sources
    - name: Loki
      type: loki
      uid: loki
      access: proxy
      url: http://loki-distributed-query-frontend-headless:3100
      # https://grafana.com/docs/grafana/latest/datasources/loki/#configure-the-data-source-with-provisioning
      jsonData:
        derivedFields:
          - name: trace_id
            datasourceUid: tempo
            matcherRegex: "trace_id=(\\w+)"
            url: "$${__value.raw}"
    - name: Prometheus
      type: prometheus
      uid: prometheus
      access: proxy
      url: http://grafana-kube-prometheus-st-prometheus:9090/
      # https://grafana.com/docs/grafana/latest/datasources/prometheus/#provision-the-prometheus-data-source
      jsonData:
        exemplarTraceIdDestinations:
          - name: trace_id
            datasourceUid: tempo
            # https://github.com/grafana-operator/grafana-operator/blob/master/api/integreatly/v1alpha1/grafanadatasource_types.go#L205
            urlDisplayLabel: View in Tempo
    - name: Tempo
      type: tempo
      uid: tempo
      access: proxy
      url: http://tempo-distributed-query-frontend-discovery:3100
      # https://grafana.com/docs/grafana/latest/datasources/tempo/#provision-the-tempo-data-source
      jsonData:
        httpMethod: GET
        nodeGraph:
          enabled: true
        serviceMap:
          datasourceUid: prometheus
        tracesToLogs:
          datasourceUid: loki
          # they must be attached by the instrumentation
          tags:
            - namespace
            - pod
          # extend time span a little, to ensure catching all logs of that span
          spanStartTimeShift: 1s
          spandEndTimeShift: 1s
          lokiSearch: true

  ## Affinity for pod assignment (evaluated as template)
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ##
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        # KISS normal control plane nodes should be preferred
        - weight: 1
          preference:
            matchExpressions:
              - key: node-role.kubernetes.io/kiss-ephemeral-control-plane
                operator: DoesNotExist
        # KISS gateway nodes should be more preferred
        - weight: 2
          preference:
            matchExpressions:
              - key: node-role.kubernetes.io/kiss
                operator: In
                values:
                  - Compute
        # KISS gateway nodes should be more preferred
        - weight: 4
          preference:
            matchExpressions:
              - key: node-role.kubernetes.io/kiss
                operator: In
                values:
                  - Gateway
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: node-role.kubernetes.io/kiss
                operator: In
                values:
                  - Compute
                  - ControlPlane
                  - Gateway

  ## Configure grafana dashboard providers
  ## ref: http://docs.grafana.org/administration/provisioning/#dashboards
  ##
  ## `path` must be /var/lib/grafana/dashboards/<provider_name>
  ##
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: default
          orgId: 1
          folder: ""
          type: file
          disableDeletion: true
          editable: false
          options:
            path: /var/lib/grafana/dashboards/default

  ## Configure grafana dashboard to import
  ## NOTE: To use dashboards you must also enable/configure dashboardProviders
  ## ref: https://grafana.com/dashboards
  ##
  ## dashboards per provider, use provider name as key.
  ##
  dashboards:
    default:
      # CSI - Rook-Ceph
      ceph-cluster:
        gnetId: 2842
        revision: 16
        datasource: Prometheus
      ceph-osd-single:
        gnetId: 5336
        revision: 9
        datasource: Prometheus
      ceph-pools:
        gnetId: 5342
        revision: 9
        datasource: Prometheus
      # Storage - S3 - MinIO
      storage-s3-minio:
        gnetId: 13502
        revision: 25
        datasource: Prometheus
      storage-s3-minio-bucket:
        gnetId: 19237
        revision: 1
        datasource: Prometheus
      storage-s3-minio-replication:
        gnetId: 15305
        revision: 4
        datasource: Prometheus
      # GPU - NVIDIA
      nvidia-dcgm-exporter-dashboard:
        gnetId: 12239
        revision: 2
        datasource: Prometheus
      # Monitoring - OpenTelemetry
      opentelemetry-collector:
        gnetId: 12553
        revision: 1
        datasource: Prometheus

  ## Grafana's primary configuration
  ## NOTE: values in map will be converted to ini format
  ## ref: http://docs.grafana.org/installation/configuration/
  ##
  grafana.ini:
    auth:
      # Disable usage of Grafana build-in login solution.
      # NOTE: it is needed to be 'false' to create a default grafana user
      disable_login: false

      # Set to true to disable (hide) the login form, useful if you use OAuth
      disable_login_form: true

      # Set to true to disable the sign out link in the side menu. Useful if you use auth.proxy or auth.jwt.
      disable_signout_menu: true

    # Anonymous Auth
    auth.anonymous:
      # enable anonymous access
      enabled: true

      # specify organization name that should be used for unauthenticated users
      # org_name: Ulagbulag Village - VINE

      # specify role for unauthenticated users
      # Available options: Admin, Editor, Viewer
      # org_role: Viewer
      org_role: Admin

    # Basic Auth
    auth.basic:
      # NOTE: it is needed to be 'true' to create a default grafana user
      enabled: true

    security:
      # set to true if you want to allow browsers to render Grafana in a <frame>, <iframe>, <embed> or <object>. default is false.
      allow_embedding: true

  ## Pass the plugins you want installed as a list.
  ##
  plugins:
    # - digrich-bubblechart-panel
    # - grafana-clock-panel
    ## You can also use other plugin download URL, as long as they are valid zip files,
    ## and specify the name of the plugin after the semicolon. Like this:
    # - https://grafana.com/api/plugins/marcusolsson-json-datasource/versions/1.3.2/download;marcusolsson-json-datasource
    - grafana-polystat-panel
    - vonage-status-panel

## Configuration for kube-state-metrics subchart
##
kube-state-metrics:
  ## Enable scraping via kubernetes-service-endpoints
  ##
  prometheusScrape: true

  prometheus:
    monitor:
      ## Enable scraping via service monitor
      ## Disable to prevent duplication if you enable prometheusScrape above
      ##
      enabled: false

    ## Create a scrapeConfig resource for scraping the kube-state-metrics service. Use this instead of serviceMonitor
    ## to have more instances of kube-state-metrics safety.
    scrapeconfig:
      ## To avoid duplicate metrics, first disable the serviceMonitor creation via prometheus.monitor.enabled=false
      enabled: true

  # List of additional cli arguments to configure kube-state-metrics
  # for example: --enable-gzip-encoding, --log-file, etc.
  # all the possible args can be found here: https://github.com/kubernetes/kube-state-metrics/blob/master/docs/cli-arguments.md
  extraArgs:
    - --metric-opt-in-list=kube_endpointslice_annotations,kube_endpointslice_info,kube_endpointslice_ports,kube_endpointslice_endpoints,kube_endpointslice_endpoints_hints,kube_endpointslice_labels,kube_endpointslice_created

  # Comma-separated list of additional Kubernetes label keys that will be used in the resource's
  # labels metric. By default the metric contains only name and namespace labels.
  # To include additional labels, provide a list of resource names in their plural form and Kubernetes
  # label keys you would like to allow for them (Example: '=namespaces=[k8s-label-1,k8s-label-n,...],pods=[app],...)'.
  # A single '*' can be provided per resource instead to allow any labels, but that has
  # severe performance implications (Example: '=pods=[*]').
  metricLabelsAllowlist:
    - endpointslices=[kubernetes.io/service-name]

  # Available collectors for kube-state-metrics.
  # By default, all available resources are enabled, comment out to disable.
  collectors:
    - certificatesigningrequests
    - configmaps
    - cronjobs
    - daemonsets
    - deployments
    - endpoints
    - endpointslices
    - horizontalpodautoscalers
    - ingresses
    - jobs
    - leases
    - limitranges
    - mutatingwebhookconfigurations
    - namespaces
    - networkpolicies
    - nodes
    - persistentvolumeclaims
    - persistentvolumes
    - poddisruptionbudgets
    - pods
    - replicasets
    - replicationcontrollers
    - resourcequotas
    - secrets
    - services
    - statefulsets
    - storageclasses
    - validatingwebhookconfigurations
    - volumeattachments

## Manages Prometheus and Alertmanager components
##
prometheusOperator:
  enabled: true

  # Enable vertical pod autoscaler support for prometheus-operator
  verticalPodAutoscaler:
    enabled: true

## Deploy a Prometheus instance
##
prometheus:
  ## Configuration for Prometheus service
  ##
  service:
    ## Loadbalancer IP
    ## Only use if service.type is "LoadBalancer"
    loadBalancerSourceRanges:
      - 10.0.0.0/8
      - 172.16.0.0/12
      - 192.168.0.0/16

    ## Service type
    ##
    type: LoadBalancer

  ## Settings affecting prometheusSpec
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#prometheusspec
  ##
  prometheusSpec:
    ## enable --web.enable-remote-write-receiver flag on prometheus-server
    ##
    enableRemoteWriteReceiver: true

    # https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml#L4041
    ## If true, a nil or {} value for prometheus.prometheusSpec.ruleSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the PrometheusRule resources created
    ##
    ruleSelectorNilUsesHelmValues: false

    # https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml#L4066
    ## If true, a nil or {} value for prometheus.prometheusSpec.serviceMonitorSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the servicemonitors created
    ##
    serviceMonitorSelectorNilUsesHelmValues: false

    ## Assign custom affinity rules to the prometheus instance
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
    ##
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          # KISS normal control plane nodes should be preferred
          - weight: 1
            preference:
              matchExpressions:
                - key: node-role.kubernetes.io/kiss-ephemeral-control-plane
                  operator: DoesNotExist
          # KISS compute nodes should be more preferred
          - weight: 2
            preference:
              matchExpressions:
                - key: node-role.kubernetes.io/kiss
                  operator: In
                  values:
                    - Compute
          # KISS gateway nodes should be more preferred
          - weight: 4
            preference:
              matchExpressions:
                - key: node-role.kubernetes.io/kiss
                  operator: In
                  values:
                    - Gateway
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: node-role.kubernetes.io/kiss
                  operator: In
                  values:
                    - Compute
                    - ControlPlane
                    - Gateway

    ## Enable/Disable Grafana dashboards provisioning for prometheus remote write feature
    remoteWriteDashboards: true

    ## Prometheus StorageSpec for persistent data
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
    ##
    storageSpec:
      ## Using PersistentVolumeClaim
      ##
      volumeClaimTemplate:
        spec:
          storageClassName: ceph-block
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 200Gi

## Configuration for prometheus-node-exporter subchart
##
prometheus-node-exporter:
  ## Assign a group of affinity scheduling rules
  ##
  affinity:
    nodeAffinity:
      # KISS ephemeral control plane nodes should be excluded
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: node-role.kubernetes.io/kiss-ephemeral-control-plane
                operator: DoesNotExist
