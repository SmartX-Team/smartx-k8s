---
kind: LLM
params:
  - name: modelName
    type: String
    default: exaone3.5:32b
  - name: name
    type: String
env:
  - name: OPENAI_MODEL_NAME
    value: {{ .params.modelName | quote }}
resources: null
srcs: null
sinks:
  - kind: Stream # Options: [Stream]
template:

{{- if not ( hasKey .params "name" ) }}
{{- fail ( printf "Missing prompt name parameter: %s" .name ) }}
{{- end }}

{{- $context := dict
  "name" .params.name
  "template" nil
}}

{{- /* Load a prompt template from extra prompts */}}
{{- range $_ := .ExtraPrompts }}
{{- if eq .name $context.name }}
{{- if empty $context.template }}
{{- $_ := set $context "template" ( .template | toYaml ) }}
{{- else }}
{{- fail ( printf "Duplicated prompt: %s" $context.name ) }}
{{- end }}
{{- end }}
{{- end }}

{{- /* Load a prompt template from builtin prompts */}}
{{- if empty $context.template }}
{{- $filePath := printf "prompts/%s.yaml" $context.name }}
{{- if not ( empty ( $.Files.Glob $filePath ) ) }}
{{- $_ := set $context "template" ( $.Files.Get $filePath ) }}
{{- else }}
{{- fail ( printf "No such prompt: %s" $context.name ) }}
{{- end }}
{{- end }}

{{- /* Remove yaml document splitter */}}
{{- if regexMatch "^---\n" $context.template }}
{{- $_ := set $context "template" ( $context.template | substr 4 ( $context.template | len ) ) }}
{{- end }}

{{- /* Render a prompt template */}}
{{- $context.template | nindent 2 }}
